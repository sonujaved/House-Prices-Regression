{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "collapsed": true,
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import norm\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import stats\nimport category_encoders as ce\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "e6a17e841fec907980c8efc89ee6fdf06eb8568d"
      },
      "cell_type": "code",
      "source": "#bring in train data\ntrain_df = pd.read_csv('../input/train.csv')\n#bring in test data\ntest_df = pd.read_csv('../input/test.csv')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "42b8784d82e0f310d880e1377cd1e856155fe3eb",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#check the numbers of samples and features\nprint(\"The train data size before dropping Id feature is : {} \".format(train_df.shape))\nprint(\"The test data size before dropping Id feature is : {} \".format(test_df.shape))\n\n#Save the 'Id' column\ntrain_ID = train_df['Id']\ntest_ID = test_df['Id']\n\n#Now drop the  'Id' colum since it's unnecessary for  the prediction process.\ntrain_df.drop(\"Id\", axis = 1, inplace = True)\ntest_df.drop(\"Id\", axis = 1, inplace = True)\n\n#check again the data size after dropping the 'Id' variable\nprint(\"\\nThe train data size after dropping Id feature is : {} \".format(train_df.shape)) \nprint(\"The test data size after dropping Id feature is : {} \".format(test_df.shape))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "3c6bc048656082c01f6d2197fc4d5126a58a7e85",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "sns.distplot(train_df[\"SalePrice\"])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "e1c5945a8f42ae8f8c360fe732aacec8245685ec",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#skewness and kurtosis\nprint(\"Skewness: %f\" % train_df['SalePrice'].skew())\nprint(\"Kurtosis: %f\" % train_df['SalePrice'].kurt())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9288184e3452202d043146a8bd13088a3075fa94",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#correlation matrix\ncorrmat = train_df.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat, vmax=.8, square=True);",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "a6b88abc79ed223fc482c0fd1e0491d1bfdcbcd8",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#applying log transformation\ntrain_df['SalePrice'] = np.log(train_df['SalePrice'])\nsns.distplot(train_df[\"SalePrice\"])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a005245212765c7f9a06be36a5c5046d0cf9b197",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#data transformation\ntrain_df['GrLivArea'] = np.log(train_df['GrLivArea'])\n#transformed histogram and normal probability plot\nsns.distplot(train_df['GrLivArea'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(train_df['GrLivArea'], plot=plt)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d7daf1fdd9469a2827df76cdc4d92fdd5578ddbf",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#data transformation\ntest_df['GrLivArea'] = np.log(test_df['GrLivArea'])\n#transformed histogram and normal probability plot\nsns.distplot(test_df['GrLivArea'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(test_df['GrLivArea'], plot=plt)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "58998ca48313aadc7593d61f5535a2c52ccc0804",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "data = [train_df, test_df]\nfor dataset in data:\n    dataset['HasBsmt'] = np.where(dataset['TotalBsmtSF'] > 0, 1, 0)\n    dataset['TotalBsmtSF'] = np.where(dataset['HasBsmt'] == 1, np.log(dataset['TotalBsmtSF']), 0)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "3c30cc11831a78c03869763ebbed67e6c87dca9b",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#histogram and normal probability plot\nsns.distplot(train_df[train_df['TotalBsmtSF']>0]['TotalBsmtSF'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(train_df[train_df['TotalBsmtSF']>0]['TotalBsmtSF'], plot=plt)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "279a6c8424443c71b6e5857a0150d665cd89a3dd",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Deleting outliers\ntrain_df = train_df.drop(train_df[(train_df['GrLivArea']>4000) & (train_df['SalePrice']<300000)].index)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "ef2afcc49e9b13a23013a6aac3fd6bcaf89d9383",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "    total = train_df.isnull().sum().sort_values(ascending=False)\n    percent = (train_df.isnull().sum()/train_df.isnull().count()).sort_values(ascending=False)\n    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    missing_data.head(20)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "124f4d48f1233403eb9031993aa75be11da08b87",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#missing data\ndata = [train_df, test_df]\nfor dataset in data:\n    dataset[\"PoolQC\"] = dataset[\"PoolQC\"].fillna(\"None\")\n    dataset[\"MiscFeature\"] = dataset[\"MiscFeature\"].fillna(\"None\")\n    dataset[\"Alley\"] = dataset[\"Alley\"].fillna(\"None\")\n    dataset[\"Fence\"] = dataset[\"Fence\"].fillna(\"None\")\n    dataset[\"FireplaceQu\"] = dataset[\"FireplaceQu\"].fillna(\"None\")\n    dataset[\"LotFrontage\"] = dataset.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))\n    dataset[\"GarageType\"] = dataset[\"GarageType\"].fillna(\"None\")\n    dataset[\"GarageFinish\"] = dataset[\"GarageFinish\"].fillna(\"None\")\n    dataset[\"GarageQual\"] = dataset[\"GarageQual\"].fillna(\"None\")\n    dataset[\"GarageCond\"] = dataset[\"GarageCond\"].fillna(\"None\")\n    dataset[\"GarageYrBlt\"] = dataset[\"GarageYrBlt\"].fillna(0)\n    dataset[\"GarageArea\"] = dataset[\"GarageArea\"].fillna(0)\n    dataset[\"GarageCars\"] = dataset[\"GarageCars\"].fillna(0)\n    dataset[\"BsmtFinSF1\"] = dataset[\"BsmtFinSF1\"].fillna(0)\n    dataset[\"BsmtFinSF2\"] = dataset[\"BsmtFinSF2\"].fillna(0)\n    dataset[\"BsmtUnfSF\"] = dataset[\"BsmtUnfSF\"].fillna(0)\n    dataset[\"TotalBsmtSF\"] = dataset[\"TotalBsmtSF\"].fillna(0)\n    dataset[\"BsmtFullBath\"] = dataset[\"BsmtFullBath\"].fillna(0)\n    dataset[\"BsmtHalfBath\"] = dataset[\"BsmtHalfBath\"].fillna(0)\n    dataset[\"BsmtQual\"] = dataset[\"BsmtQual\"].fillna(\"None\")\n    dataset[\"BsmtCond\"] = dataset[\"BsmtCond\"].fillna(\"None\")\n    dataset[\"BsmtExposure\"] = dataset[\"BsmtExposure\"].fillna(\"None\")\n    dataset[\"BsmtFinType1\"] = dataset[\"BsmtFinType1\"].fillna(\"None\")\n    dataset[\"BsmtFinType2\"] = dataset[\"BsmtFinType2\"].fillna(\"None\")\n    dataset[\"MasVnrType\"] = dataset[\"MasVnrType\"].fillna(\"None\")\n    dataset[\"MasVnrArea\"] = dataset[\"MasVnrArea\"].fillna(0)\n    dataset['MSZoning'] = dataset['MSZoning'].fillna(dataset['MSZoning'].mode()[0])\n    dataset = dataset.drop(['Utilities'], axis=1)\n    dataset[\"Functional\"] = dataset[\"Functional\"].fillna(\"Typ\")\n    dataset['Electrical'] = dataset['Electrical'].fillna(dataset['Electrical'].mode()[0])\n    dataset['KitchenQual'] = dataset['KitchenQual'].fillna(dataset['KitchenQual'].mode()[0])\n    dataset['Exterior1st'] = dataset['Exterior1st'].fillna(dataset['Exterior1st'].mode()[0])\n    dataset['Exterior2nd'] = dataset['Exterior2nd'].fillna(dataset['Exterior2nd'].mode()[0])\n    dataset['SaleType'] = dataset['SaleType'].fillna(dataset['SaleType'].mode()[0])\n    dataset['MSSubClass'] = dataset['MSSubClass'].fillna(\"None\") \n    #MSSubClass=The building class\n    dataset['MSSubClass'] = dataset['MSSubClass'].apply(str)\n    #Changing OverallCond into a categorical variable\n    dataset['OverallCond'] = dataset['OverallCond'].astype(str)\n    #Year and month sold are transformed into categorical features.\n    dataset['YrSold'] = dataset['YrSold'].astype(str)\n    dataset['MoSold'] = dataset['MoSold'].astype(str)\n    dataset_na = (dataset.isnull().sum() / len(dataset)) * 100\n    dataset_na = dataset_na.drop(dataset_na[dataset_na == 0].index).sort_values(ascending=False)\nmissing_data = pd.DataFrame({'Missing Ratio' :dataset_na})\nmissing_data.head()\n\n    \n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "93da9b3ddac38d115302e0e4d5f526e18527ad06",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train_df.shape\ntest_df.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "8e19c6457d578b358b4e95cd841c570abded302e",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import category_encoders as ce\n\nX = train_df\ny = train_df[\"SalePrice\"]\ny_train = train_df.SalePrice.values\ntrain_df.drop('SalePrice',axis = 1,inplace=True)\n\nencoder = ce.TargetEncoder(cols=['YrSold', 'MoSold'])\nencoder.fit(X, y)\ntrain_df = encoder.transform(X)\n\nX = test_df\ntest_df = encoder.transform(X,y=None)\n\n#encoder = ce.BinaryEncoder(cols=['FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n#        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n#        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n#        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond']).fit(X, y)\n#train_df = encoder.transform(X)\n#X = test_df\n#test_df = encoder.transform(X)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bf2268b5e89a7aa6c3423087d52a36c5bc9f94f2",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "y_train",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1ff969b830f3c60551a49b33522dd18a8311f22b",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train_df.shape+test_df.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fc38774fd449de50241f04a673afad3e4d945f88",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#new\ndata = [train_df, test_df]\nfor dataset in data:\n# Adding total sqfootage feature \n    dataset['TotalSF'] = dataset['TotalBsmtSF'] + dataset['1stFlrSF'] + dataset['2ndFlrSF']\n    ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "74b56b86c153a4c40289fa685552f13aa4eb9871",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "from scipy import stats\nfrom scipy.stats import norm, skew #for some statistics\n\nntrain = train_df.shape[0]\nntest = test_df.shape[0]\nall_data = pd.concat((train_df, test_df)).reset_index(drop=True)\n#all_data.drop(['SalePrice'], axis=1, inplace=True)\nprint(\"all_data size is : {}\".format(all_data.shape))\n\nnumeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n\n# Check the skew of all numerical features\nskewed_feats = all_data[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\nprint(\"\\nSkew in numerical features: \\n\")\nskewness = pd.DataFrame({'Skew' :skewed_feats})\nskewness.head(10)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "_uuid": "b90853d871f7a65bf849dce63b46d1a52a80e75b",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "skewness = skewness[abs(skewness) > 0.75]\nprint(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n\nfrom scipy.special import boxcox1p\nskewed_features = skewness.index\nlam = 0.15\nfor feat in skewed_features:\n    #all_data[feat] += 1\n    all_data[feat] = boxcox1p(all_data[feat], lam)\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c893031a879ba945db23894575a5b32413c6e677",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "all_data = pd.get_dummies(all_data)\nprint(all_data.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "ac939dcae70c8e42f194398794986afcb7a65bb0",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train = all_data[:ntrain]\ntest = all_data[ntrain:]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "664dd09ce7ac271543d7863a605d424858fedc97",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\n\n#model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n#                              learning_rate=0.05, n_estimators=720,\n#                              max_bin = 55, bagging_fraction = 0.8,\n#                              bagging_freq = 5, feature_fraction = 0.2319,\n#                              feature_fraction_seed=9, bagging_seed=9,\n#                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\n\nmodel_lgb = lgb.LGBMRegressor(objective='regression',\n                              boosting='dart',\n                              num_leaves=5,\n                              learning_rate=0.05, \n                              n_estimators=700,\n                              max_bin = 55, \n                              bagging_fraction = 0.8,\n                              bagging_freq = 5, \n                              feature_fraction = 0.2319,\n                              feature_fraction_seed=9, \n                              bagging_seed=9,\n                              min_data_in_leaf =6, \n                              min_sum_hessian_in_leaf = 11)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "5a8e2059c0e06421885600c14aa7d5b1dbc41465"
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import mean_squared_error\ndef rmsle(y, y_pred):\n    return np.sqrt(mean_squared_error(y, y_pred))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "417b93be30d6746640f11a2639b6f81a5ec9da35",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "model_lgb.fit(train, y_train)\nlgb_train_pred = model_lgb.predict(train)\nlgb_pred = np.expm1(model_lgb.predict(test.values))\nprint(rmsle(y_train, lgb_train_pred))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "00b4e5d9ef78131133dfd2acae38aa5ef83f04f8"
      },
      "cell_type": "code",
      "source": "import xgboost as xgb\nmodel_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n                             learning_rate=0.1, max_depth=4, \n                             min_child_weight=1.7817, n_estimators=3000,\n                             reg_alpha=0.4640, reg_lambda=0.8571,\n                             subsample=0.5, silent=1,\n                             random_state =7, nthread = -1)\n#subsample=0.5213, nthread = -1, n_estimators=3000",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "457aa778583fd7161d3010ca63db5da5cfdedb57",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "model_xgb.fit(train, y_train)\nxgb_train_pred = model_xgb.predict(train)\nxgb_pred = np.expm1(model_xgb.predict(test))\nprint(rmsle(y_train, xgb_train_pred))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5f308b8c993ac6554d51fd761ade34c859f293ef",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\nGBoost = GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n             learning_rate=0.1, loss='huber', max_depth=4,\n             max_features='sqrt', max_leaf_nodes=None,\n             min_impurity_decrease=0.0, min_impurity_split=None,\n             min_samples_leaf=15, min_samples_split=10,\n             min_weight_fraction_leaf=0.0, n_estimators=3000,\n             presort='auto', random_state=None, subsample=1.0, verbose=0,\n             warm_start=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "586f7404c42516efd779e091ba721fdff493f9f4",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "GBoost.fit(train, y_train)\ngb_train_pred = GBoost.predict(train)\ngb_pred = np.expm1(GBoost.predict(test))\nprint(rmsle(y_train, gb_train_pred))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4ac191fd7092700c7301044257602505337ee4dd",
        "scrolled": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "xgb_pred",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ce65f1b0e9aba6ae352322f7a5c6756be43a8b66",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "lgb_pred",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f7431156164fb1466eb638f870d9a9d2db192098",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "gb_pred",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a9d5567b7ad2eb70d6929c7ad784148b52e72e72",
        "scrolled": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "Final=(lgb_pred + gb_pred + xgb_pred )/3\nPrice = Final.astype(np.int64)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "032593ee572cd0fb93697d3dccb6a61c1b03acad",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "sub = pd.DataFrame()\nsub['Id'] = test_ID\nsub['SalePrice'] = Price\nsub.to_csv('submission.csv',index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5bf2e2100cfe28783b1113be14aca4961cc5c1b5",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "sub",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}